# Building a proactive agent from first principles

I got interested in agents around Septemeber 2023 and started by prototyping with gpt-3.5 and gpt-4. We've come a long way since then, but a lot of the core concepts remain the same.

Last year around January 2024 I started my own company called Extensible AI where we worked on agent reliability. It was probably a bit too early to work on agent reliability but it taught me a lot about what worked and didn't work when it came to building agents. 

Good software is often decomposed as Directed Acyclic Graphs (DAGs). Agents take parts of this software and make it into more of a black box, where the DAG is generated by the model in a sense to go from a goal to an action in a loop. I personally like the DAG idea quite a bit - so much so I built [DAGent](https://github.com/Extensible-AI/DAGent) last year to deal with models not being as good with *agentic tool use* (we'll cover this soon).

I think I've collected some interesting learnings over the last couple years and thought I'd share some of them here. Most recently, I've been very intrigued with agents which initiate actions without being prompted by the end user. I use poke to run simple things and I'll attempt to build a tiny version of it. 

I'll also focus more on open-source models as they've come a long way from last year and if you're a bit clever with how you use them, you can build some really cool stuff. 

# Anatomy of an agent

The most common way to build an agent with capable models is to throw it into a loop with a goal and a set of tools. The following is a simple single agent execution loop:
```
goal = "do x for me"
message_history = [goal]
while true:
    response = model.generate(message_history, available_tools)
    if tool_calls:
        result = execute_tool(tool_calls)
        message_history.append(result)
    else:
        print(response)
        break
```

In the above loop, the exit condition for the model is that there are no more tools to call and it has reached a final response. You may choose to give the model the ability to end the loop itself - but I've personally never found a model to always make a good decision to "end" a loop. It often prefers a "pass" or a "continue" tool. Experimentation with your use case is best here.

Models like `qwen3-coder`, `GLM-4.6`, and `gpt-oss` tend to perform well an agent loop. These models have an understanding of how to use tools they are provided and are able to go from a provided goal to conducting actions to reach that goal. 

# Building a simple agent

Here is a simple agent which uses a tool to search the web and then summarize the results:

```python
```



# Context engineering for agents

tool design -> anthropic

# Why are proactive agents different

# Building "Poke At Home" 
## idea
## tool design
## testing the agent
## emergent behaviors
## polling vs notifications
### cdc
### webhooks


# context engineering for agents
## proactive agents
